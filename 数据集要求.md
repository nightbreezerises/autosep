# AutoSEP 数据集要求文档

## 概述
AutoSEP (Automatic Self-Enhancing Prompt Learning) 是一个用于细粒度图像零样本分类的多模态大语言模型框架。本文档详细说明了新数据集的格式要求和处理流程。

## 当前支持的数据集
- **CUB-200-2011**: 鸟类细粒度分类数据集
  - 子任务: `CUB_cuckoo`, `CUB_oriole`, `CUB_vireo`
- **iNaturalist**: 自然物种分类数据集
  - 子任务: `iNat_butterfly`, `iNat_lupine`
- **Stanford Dogs**: 狗类细粒度分类数据集
  - 子任务: `Stanford_terrier`
- **VegFru**: 蔬菜水果分类数据集
  - 子任务: `vegfru_greens`, `vegfru_allium`

## 数据集目录结构要求

### 基本目录结构
```
datasets/
├── [数据集名称]/
│   ├── images/                    # 图像文件夹
│   │   ├── [类别1]/
│   │   │   ├── image1.jpg
│   │   │   └── image2.jpg
│   │   └── [类别2]/
│   │       ├── image1.jpg
│   │       └── image2.jpg
│   ├── train.pkl                  # 训练集元数据
│   ├── val.pkl                    # 验证集元数据 (可选)
│   ├── test.pkl                   # 测试集元数据
│   └── classes.txt                # 类别名称文件
```

### CUB数据集特殊结构 (参考示例)
```
CUB-200-2011/
├── CUB_200_2011/                  # 原始数据
│   ├── images/
│   ├── attributes/
│   │   ├── attributes.txt
│   │   └── image_attribute_labels.txt
│   ├── classes.txt
│   ├── images.txt
│   └── train_test_split.txt
├── CUB_processed/                 # 处理后的数据
│   └── class_attr_data_10/
│       ├── train.pkl
│       ├── val.pkl
│       └── test.pkl
├── CUB_raw/                       # 原始处理数据
└── CUB_unvoted/                   # 未投票的属性数据
```

## 元数据格式要求

### PKL文件格式
每个pkl文件包含一个字典列表，每个字典代表一个样本：

```python
{
    'id': str,                     # 样本唯一标识符，格式: "train-0", "test-1"
    'img_path': str,               # 图像文件的绝对路径
    'class_label': int,            # 类别标签 (0-based索引)
    'label_name': str,             # 类别名称 (可读字符串)
    'attribute_label': list,       # 属性标签列表 (可选，用于细粒度分类)
    'attribute_certainty': list,   # 属性确定性列表 (可选)
    'uncertain_attribute_label': list  # 不确定属性标签 (可选)
}
```

### 类别文件格式 (classes.txt)
```
0 类别名称1
1 类别名称2
2 类别名称3
...
```

## 数据集处理流程

### 1. 数据预处理
- 图像格式: 支持 JPG, PNG 等常见格式
- 图像尺寸: 无特殊要求，模型会自动处理
- 类别数量: 建议2-200个类别

### 2. 数据划分要求
- **训练集**: 用于提示优化，每个类别建议30个样本
- **验证集**: 用于模型选择 (可选)，每个类别建议30个样本  
- **测试集**: 用于最终评估，每个类别建议30个样本

### 3. 属性标注 (可选)
对于细粒度分类任务，可以添加属性标注：
- 属性数量: 建议100-400个属性
- 属性类型: 二值属性 (0/1) 或连续属性
- 确定性标注: 1=不可见, 2=猜测, 3=可能, 4=确定

## 新数据集集成步骤

### 1. 准备数据文件
```bash
# 创建数据集目录
mkdir datasets/[新数据集名称]

# 组织图像文件
mkdir datasets/[新数据集名称]/images
# 将图像按类别放入子文件夹
```

### 2. 生成元数据文件
```python
# 参考 datasets/process_cub.py 中的处理逻辑
# 生成 train.pkl, val.pkl, test.pkl 文件
```

### 3. 创建任务类
在 `tasks.py` 中添加新的任务类：
```python
class NewDatasetTask(MyClassificationTask):
    def __init__(self, data_dir, file_name, max_threads, args):
        super().__init__(data_dir, file_name, max_threads)
        # 定义类别映射
        self.num2classname = ['类别1', '类别2', '类别3']
        self.name2label = {'类别1': 0, '类别2': 1, '类别3': 2}
    
    def get_examples(self, mode='train'):
        # 实现数据加载逻辑
        pass
```

### 4. 更新配置文件
在 `get_utils.py` 中添加新任务的支持：
```python
def get_task_class(args):
    if 'new_dataset' in args.task_name:
        return tasks.NewDatasetTask(args.data_dir, None, args.max_threads, args)
    # ... 其他数据集
```

### 5. 更新参数选择
在各个 `main.py` 文件中添加新的 task_name 选项。

## 注意事项

1. **路径处理**: 确保所有图像路径都是绝对路径
2. **类别一致性**: 确保类别标签在所有数据分割中保持一致
3. **数据平衡**: 建议每个类别的样本数量相对平衡
4. **文件编码**: 所有文本文件使用UTF-8编码
5. **内存考虑**: 大型数据集建议分批处理，避免内存溢出

## 验证数据集
创建数据集后，可以使用以下命令验证：
```bash
python -c "
import pickle
data = pickle.load(open('datasets/[数据集名称]/train.pkl', 'rb'))
print(f'训练集样本数: {len(data)}')
print(f'样本格式: {data[0].keys()}')
"
```
