# 数据集新增指南

## 一、已支持的数据集

### 1.1 细粒度分类数据集

| 简称 | 全称 | 类别数 | 说明 |
|------|------|--------|------|
| `cub` | CUB-200-2011 | 200 | 鸟类细粒度分类 |
| `dog` | Stanford Dogs | 120 | 狗品种分类 |
| `flower` | Oxford Flowers | 102 | 花卉分类 |
| `car` | Stanford Cars | 196 | 汽车型号分类 |
| `pet` | Oxford Pets | 37 | 宠物分类 |
| `aircraft` | FGVC Aircraft | 100 | 飞机型号分类 |
| `food` | Food-101 | 101 | 食物分类 |
| `birdsnap` | Birdsnap | 500 | 鸟类分类 |

### 1.2 通用分类数据集

| 简称 | 全称 | 类别数 | 说明 |
|------|------|--------|------|
| `caltech101` | Caltech-101 | 101 | 通用物体分类 |
| `caltech256` | Caltech-256 | 256 | 通用物体分类 |
| `dtd` | DTD | 47 | 纹理分类 |
| `eurosat` | EuroSAT | 10 | 卫星图像分类 |
| `ucf` | UCF-101 | 101 | 动作识别 |
| `sun397` | SUN397 | 397 | 场景分类 |

### 1.3 ImageNet 系列

| 简称 | 全称 | 类别数 | 说明 |
|------|------|--------|------|
| `imagenet_1k` | ImageNet-1K | 1000 | 通用分类基准 |
| `imagenet_a` | ImageNet-A | 200 | 对抗样本 |
| `imagenet_r` | ImageNet-R | 200 | 渲染图像 |
| `imagenet_sketch` | ImageNet-Sketch | 1000 | 素描图像 |
| `imagenet_v2` | ImageNet-V2 | 1000 | ImageNet 变体 |

## 二、数据集目录结构

所有数据集位于 `datasets/` 目录下，支持两种目录结构：

### 单层结构（推荐）

```
datasets/
└── {数据集目录名}/
    ├── Images/                    # 图片目录（注意大小写可能不同）
    │   ├── class_1/
    │   ├── class_2/
    │   └── ...
    └── images_split/
        └── split_datasets_images.json
```

### 双层结构（兼容 CUB 等数据集）

```
datasets/
└── {数据集目录名}/
    └── {数据集目录名}/
        ├── images/
        └── images_split/
            └── split_datasets_images.json
```

**注意**: 
- 系统会自动检测目录结构，优先使用单层结构
- 划分文件名优先使用 `split_datasets_images.json`，兼容 `split_dataset_images.json`

### 2.1 split_datasets_images.json 格式

**重要**: 每个样本是一个三元组 `[类别名, 类别ID, 相对图片路径]`

```json
{
    "train": [
        ["类别名称", 类别ID, "相对图片路径"],
        ["类别名称", 类别ID, "相对图片路径"],
        ...
    ],
    "val": [
        ...
    ],
    "test": [
        ...
    ]
}
```

**字段说明**：
- **类别名称**: 字符串，如 `"001.Black_footed_Albatross"`
- **类别ID**: 整数，从 0 开始的类别索引
- **相对图片路径**: 相对于数据集根目录的路径，如 `"images/001.xxx/xxx.jpg"`

**示例**：

dogs_120:
```json
{
    "train": [
        ["Afghan_hound", 0, "Images/n02088094-Afghan_hound/n02088094_3396.jpg"],
        ["Afghan_hound", 0, "Images/n02088094-Afghan_hound/n02088094_3850.jpg"]
    ],
    "test": [...]
}
```

flowers_102:
```json
{
    "train": [
        ["alpine sea holly", 0, "jpg/image_06992.jpg"],
        ["alpine sea holly", 0, "jpg/image_06986.jpg"]
    ],
    "test": [...]
}
```

CUB_200_2011:
```json
{
    "train": [
        ["001.Black_footed_Albatross", 0, "CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0014_89.jpg"],
        ["001.Black_footed_Albatross", 0, "CUB_200_2011/images/001.Black_footed_Albatross/Black_Footed_Albatross_0056_796078.jpg"]
    ],
    "test": [...]
}
```

## 三、新增数据集步骤

### 步骤 1: 准备数据集目录

```bash
# 创建数据集目录（或创建符号链接）
mkdir -p datasets/{数据集名}/{数据集名}/images_split

# 或使用符号链接指向已有数据
ln -s /path/to/your/dataset datasets/{数据集名}
```

### 步骤 2: 生成划分文件

创建 `split_datasets_images.json` 文件，包含训练集和测试集的图片路径。

可以使用以下 Python 脚本生成：

```python
import os
import json
from sklearn.model_selection import train_test_split

def generate_split_file(dataset_dir, images_subdir, output_path, test_ratio=0.2, val_ratio=0.1):
    """
    生成数据集划分文件
    
    Args:
        dataset_dir: 数据集根目录 (包含 images/ 的目录)
        images_subdir: 图片子目录名，如 'images'
        output_path: 输出 JSON 文件路径
        test_ratio: 测试集比例
        val_ratio: 验证集比例
    """
    split_data = {"train": [], "val": [], "test": []}
    images_dir = os.path.join(dataset_dir, images_subdir)
    
    # 获取所有类别并排序
    class_names = sorted([d for d in os.listdir(images_dir) 
                          if os.path.isdir(os.path.join(images_dir, d))])
    
    for class_id, class_name in enumerate(class_names):
        class_dir = os.path.join(images_dir, class_name)
        
        # 获取所有图片
        images = sorted([
            f for f in os.listdir(class_dir) 
            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))
        ])
        
        # 划分训练集、验证集和测试集
        if len(images) > 2:
            train_imgs, test_imgs = train_test_split(
                images, test_size=test_ratio, random_state=42
            )
            if val_ratio > 0 and len(train_imgs) > 1:
                train_imgs, val_imgs = train_test_split(
                    train_imgs, test_size=val_ratio/(1-test_ratio), random_state=42
                )
            else:
                val_imgs = []
        else:
            train_imgs, val_imgs, test_imgs = images, [], []
        
        # 添加到划分数据（使用相对路径）
        for img in train_imgs:
            rel_path = f"{images_subdir}/{class_name}/{img}"
            split_data["train"].append([class_name, class_id, rel_path])
        for img in val_imgs:
            rel_path = f"{images_subdir}/{class_name}/{img}"
            split_data["val"].append([class_name, class_id, rel_path])
        for img in test_imgs:
            rel_path = f"{images_subdir}/{class_name}/{img}"
            split_data["test"].append([class_name, class_id, rel_path])
    
    # 保存
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w') as f:
        json.dump(split_data, f, indent=2)
    
    print(f"生成完成: {output_path}")
    print(f"类别数: {len(class_names)}")
    print(f"训练集: {len(split_data['train'])} 张")
    print(f"验证集: {len(split_data['val'])} 张")
    print(f"测试集: {len(split_data['test'])} 张")

# 使用示例
generate_split_file(
    dataset_dir="/path/to/datasets/your_dataset",
    images_subdir="images",
    output_path="/path/to/datasets/your_dataset/images_split/split_datasets_images.json"
)
```

### 步骤 3: 添加数据集映射（可选）

如果数据集简称与目录名不同，需要在 `data/dataset_config.py` 中添加映射：

```python
# 在 DATASET_MAPPING 中添加
DATASET_MAPPING = {
    # ... 已有映射
    'my_dataset': 'MyDataset_Directory',  # 简称 -> 目录名
}

# 在 DATASET_INFO 中添加（可选，用于显示信息）
DATASET_INFO = {
    # ... 已有信息
    'my_dataset': {'name': 'My Dataset', 'classes': 100, 'type': '自定义分类'},
}
```

### 步骤 4: 运行测试

```bash
# 修改配置文件
vim scripts/config.yaml
# 设置 dataset: my_dataset

# 运行
bash scripts/run_pipeline.sh
```

## 四、配置文件说明

在 `scripts/config.yaml` 中设置数据集：

```yaml
# 数据集名称（使用简称）
dataset: cub

# 支持的数据集简称:
# 细粒度: cub, dog, flower, car, pet, aircraft, food, birdsnap
# 通用: caltech101, caltech256, dtd, eurosat, ucf, sun397
# ImageNet: imagenet_1k, imagenet_a, imagenet_r, imagenet_sketch, imagenet_v2
```

## 五、常见问题

### Q1: 数据集加载失败？

检查以下几点：
1. `split_datasets_images.json` 或 `split_dataset_images.json` 文件是否存在
2. JSON 文件格式是否正确（每个样本是 `[类别名, 类别ID, 相对路径]` 三元组）
3. 图片路径是否为**相对路径**（相对于 `images_split` 所在目录）
4. 图片文件是否存在

### Q2: 如何使用自定义 Prompt？

在 `prompts/` 目录下创建：
- `{数据集名}_generate.md` - 描述生成 Prompt
- `{数据集名}_multi.md` - 分类预测 Prompt

如果不创建，系统会使用默认的通用 Prompt 模板。

### Q3: 如何调整训练/测试样本数？

修改 `scripts/config.yaml`：

```yaml
autosep:
  n_train: 30   # 训练样本数
  n_test: 30    # 测试样本数

classification:
  n_test: 30    # 评估测试样本数
```

## 六、数据集目录映射表

| 简称 | 目录名 |
|------|--------|
| cub | CUB_200_2011 |
| dog | dogs_120 |
| flower | flowers_102 |
| car | car_196 |
| pet | pet_37 |
| aircraft | fgvc_aircraft |
| food | food_101 |
| birdsnap | birdsnap |
| caltech101 | caltech101 |
| caltech256 | caltech256 |
| dtd | dtd |
| eurosat | eurosat |
| ucf | ucf101 |
| sun397 | SUN397 |
| imagenet_1k | ImageNet_1k |
| imagenet_a | ImageNet_A |
| imagenet_r | ImageNet_R |
| imagenet_sketch | ImageNet_Sketch |
| imagenet_v2 | ImageNet_v2 |
