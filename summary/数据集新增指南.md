# 数据集新增指南

## 一、已支持的数据集

### 1.1 细粒度分类数据集

| 简称 | 全称 | 类别数 | 说明 |
|------|------|--------|------|
| `cub` | CUB-200-2011 | 200 | 鸟类细粒度分类 |
| `dog` | Stanford Dogs | 120 | 狗品种分类 |
| `flower` | Oxford Flowers | 102 | 花卉分类 |
| `car` | Stanford Cars | 196 | 汽车型号分类 |
| `pet` | Oxford Pets | 37 | 宠物分类 |
| `aircraft` | FGVC Aircraft | 100 | 飞机型号分类 |
| `food` | Food-101 | 101 | 食物分类 |
| `birdsnap` | Birdsnap | 500 | 鸟类分类 |

### 1.2 通用分类数据集

| 简称 | 全称 | 类别数 | 说明 |
|------|------|--------|------|
| `caltech101` | Caltech-101 | 101 | 通用物体分类 |
| `caltech256` | Caltech-256 | 256 | 通用物体分类 |
| `dtd` | DTD | 47 | 纹理分类 |
| `eurosat` | EuroSAT | 10 | 卫星图像分类 |
| `ucf` | UCF-101 | 101 | 动作识别 |
| `sun397` | SUN397 | 397 | 场景分类 |

### 1.3 ImageNet 系列

| 简称 | 全称 | 类别数 | 说明 |
|------|------|--------|------|
| `imagenet_1k` | ImageNet-1K | 1000 | 通用分类基准 |
| `imagenet_a` | ImageNet-A | 200 | 对抗样本 |
| `imagenet_r` | ImageNet-R | 200 | 渲染图像 |
| `imagenet_sketch` | ImageNet-Sketch | 1000 | 素描图像 |
| `imagenet_v2` | ImageNet-V2 | 1000 | ImageNet 变体 |

## 二、数据集目录结构

所有数据集位于 `datasets/` 目录下，支持两种目录结构：

### 单层结构（推荐）

```
datasets/
└── {数据集目录名}/
    ├── images/                    # 图片目录
    │   ├── class_1/
    │   ├── class_2/
    │   └── ...
    └── images_split/
        └── split_dataset_images.json
```

### 双层结构（兼容 CUB 等数据集）

```
datasets/
└── {数据集目录名}/
    └── {数据集目录名}/
        ├── images/
        └── images_split/
            └── split_dataset_images.json
```

**注意**: 系统会自动检测目录结构，优先使用单层结构。

### 2.1 split_dataset_images.json 格式

```json
{
    "train": {
        "类别名1": ["图片路径1", "图片路径2", ...],
        "类别名2": ["图片路径1", "图片路径2", ...],
        ...
    },
    "test": {
        "类别名1": ["图片路径1", "图片路径2", ...],
        "类别名2": ["图片路径1", "图片路径2", ...],
        ...
    }
}
```

**示例**：
```json
{
    "train": {
        "Black_footed_Albatross": [
            "/path/to/datasets/CUB_200_2011/images/001.Black_footed_Albatross/Black_footed_Albatross_0001.jpg",
            "/path/to/datasets/CUB_200_2011/images/001.Black_footed_Albatross/Black_footed_Albatross_0002.jpg"
        ],
        "Laysan_Albatross": [
            "/path/to/datasets/CUB_200_2011/images/002.Laysan_Albatross/Laysan_Albatross_0001.jpg"
        ]
    },
    "test": {
        "Black_footed_Albatross": [
            "/path/to/datasets/CUB_200_2011/images/001.Black_footed_Albatross/Black_footed_Albatross_0046.jpg"
        ]
    }
}
```

## 三、新增数据集步骤

### 步骤 1: 准备数据集目录

```bash
# 创建数据集目录（或创建符号链接）
mkdir -p datasets/{数据集名}/{数据集名}/images_split

# 或使用符号链接指向已有数据
ln -s /path/to/your/dataset datasets/{数据集名}
```

### 步骤 2: 生成划分文件

创建 `split_dataset_images.json` 文件，包含训练集和测试集的图片路径。

可以使用以下 Python 脚本生成：

```python
import os
import json
from sklearn.model_selection import train_test_split

def generate_split_file(dataset_dir, output_path, test_ratio=0.2):
    """
    生成数据集划分文件
    
    Args:
        dataset_dir: 数据集图片目录（包含各类别子目录）
        output_path: 输出 JSON 文件路径
        test_ratio: 测试集比例
    """
    split_data = {"train": {}, "test": {}}
    
    for class_name in os.listdir(dataset_dir):
        class_dir = os.path.join(dataset_dir, class_name)
        if not os.path.isdir(class_dir):
            continue
        
        # 获取所有图片
        images = [
            os.path.join(class_dir, f) 
            for f in os.listdir(class_dir) 
            if f.lower().endswith(('.jpg', '.jpeg', '.png'))
        ]
        
        # 划分训练集和测试集
        if len(images) > 1:
            train_imgs, test_imgs = train_test_split(
                images, test_size=test_ratio, random_state=42
            )
        else:
            train_imgs, test_imgs = images, []
        
        split_data["train"][class_name] = train_imgs
        split_data["test"][class_name] = test_imgs
    
    # 保存
    with open(output_path, 'w') as f:
        json.dump(split_data, f, indent=2)
    
    print(f"生成完成: {output_path}")
    print(f"类别数: {len(split_data['train'])}")
    print(f"训练集: {sum(len(v) for v in split_data['train'].values())} 张")
    print(f"测试集: {sum(len(v) for v in split_data['test'].values())} 张")

# 使用示例
generate_split_file(
    dataset_dir="/path/to/your/dataset/images",
    output_path="/path/to/your/dataset/images_split/split_dataset_images.json"
)
```

### 步骤 3: 添加数据集映射（可选）

如果数据集简称与目录名不同，需要在 `data/dataset_config.py` 中添加映射：

```python
# 在 DATASET_MAPPING 中添加
DATASET_MAPPING = {
    # ... 已有映射
    'my_dataset': 'MyDataset_Directory',  # 简称 -> 目录名
}

# 在 DATASET_INFO 中添加（可选，用于显示信息）
DATASET_INFO = {
    # ... 已有信息
    'my_dataset': {'name': 'My Dataset', 'classes': 100, 'type': '自定义分类'},
}
```

### 步骤 4: 运行测试

```bash
# 修改配置文件
vim scripts/config.yaml
# 设置 dataset: my_dataset

# 运行
bash scripts/run_pipeline.sh
```

## 四、配置文件说明

在 `scripts/config.yaml` 中设置数据集：

```yaml
# 数据集名称（使用简称）
dataset: cub

# 支持的数据集简称:
# 细粒度: cub, dog, flower, car, pet, aircraft, food, birdsnap
# 通用: caltech101, caltech256, dtd, eurosat, ucf, sun397
# ImageNet: imagenet_1k, imagenet_a, imagenet_r, imagenet_sketch, imagenet_v2
```

## 五、常见问题

### Q1: 数据集加载失败？

检查以下几点：
1. `split_dataset_images.json` 文件是否存在
2. JSON 文件格式是否正确
3. 图片路径是否为绝对路径
4. 图片文件是否存在

### Q2: 如何使用自定义 Prompt？

在 `prompts/` 目录下创建：
- `{数据集名}_generate.md` - 描述生成 Prompt
- `{数据集名}_multi.md` - 分类预测 Prompt

如果不创建，系统会使用默认的通用 Prompt 模板。

### Q3: 如何调整训练/测试样本数？

修改 `scripts/config.yaml`：

```yaml
autosep:
  n_train: 30   # 训练样本数
  n_test: 30    # 测试样本数

classification:
  n_test: 30    # 评估测试样本数
```

## 六、数据集目录映射表

| 简称 | 目录名 |
|------|--------|
| cub | CUB_200_2011 |
| dog | dogs_120 |
| flower | flowers_102 |
| car | car_196 |
| pet | pet_37 |
| aircraft | fgvc_aircraft |
| food | food_101 |
| birdsnap | birdsnap |
| caltech101 | caltech101 |
| caltech256 | caltech256 |
| dtd | dtd |
| eurosat | eurosat |
| ucf | ucf101 |
| sun397 | SUN397 |
| imagenet_1k | ImageNet_1k |
| imagenet_a | ImageNet_A |
| imagenet_r | ImageNet_R |
| imagenet_sketch | ImageNet_Sketch |
| imagenet_v2 | ImageNet_v2 |
