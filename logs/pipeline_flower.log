å·²æ¿€æ´» conda ç¯å¢ƒ: autosep
============================================================
AutoSEP Pipeline
é…ç½®æ–‡ä»¶: /home/hdl/data/project/autosep/scripts/config.yaml
é¡¹ç›®æ ¹ç›®å½•: /home/hdl/data/project/autosep
æ—¥å¿—æ–‡ä»¶: /home/hdl/data/project/autosep/logs/pipeline_flower(1).log
============================================================
è®¾ç½® CUDA_VISIBLE_DEVICES=1
è°ƒè¯•æ¯”ä¾‹: train_ratio=10.0%, test_ratio=10.0%
AutoSEP æœ‰æ•ˆæ ·æœ¬æ•°: n_train=3, n_val=3, n_test=3
åˆ†ç±»è¯„ä¼°æœ‰æ•ˆæ ·æœ¬æ•°: n_test=3
è®¾ç½® AUTOSEP_MODEL=Qwen2.5-VL-7B-Instruct

============================================================
é…ç½®ä¿¡æ¯
============================================================
æ•°æ®é›†ç®€ç§°: flower
ç›®å½•å: flowers_102
å…¨ç§°: Oxford Flowers
ç±»åˆ«æ•°: 102
ç±»å‹: èŠ±å‰åˆ†ç±»
è·¯å¾„: /home/hdl/data/project/autosep/datasets/flowers_102 âœ“

è¿è¡Œå‚æ•°:
  æ•°æ®ç›®å½•: ./datasets
  æ¨¡å‹: Qwen2.5-VL-7B-Instruct
  GPU: 1
  å®éªŒç¼–å·: 1

æ”¯æŒçš„æ¨¡å‹:
  - Qwen2.5-VL-7B-Instruct (é»˜è®¤)
  - Qwen3-VL-8B-Instruct

æ”¯æŒçš„æ•°æ®é›†:
  ç»†ç²’åº¦: cub, dog, flower, car, pet, aircraft, food, birdsnap
  é€šç”¨:   caltech101, caltech256, dtd, eurosat, ucf, sun397
  ImageNet: imagenet_1k, imagenet_a, imagenet_r, imagenet_sketch, imagenet_v2
============================================================

å¼€å§‹å¤„ç†: æ•°æ®é›†=flower, æ¨¡å‹=Qwen2.5-VL-7B-Instruct
============================================================

[Step 1/2] è¿è¡Œ AutoSEP ä¼˜åŒ–...

[DatasetLoader] åŠ è½½æ•°æ®é›†: flower -> flowers_102
  - è·¯å¾„: /data/oldhome/gwj_sdc/hdl/project/autosep/datasets/flowers_102
  - åˆ’åˆ†æ–‡ä»¶: split_datasets_images.json
  - ç±»åˆ«æ•°: 102
  - è®­ç»ƒé›†: 6507 æ ·æœ¬
  - éªŒè¯é›†: 0 æ ·æœ¬
  - æµ‹è¯•é›†: 1682 æ ·æœ¬
[load_prompts] ä½¿ç”¨é»˜è®¤ prompt æ¨¡æ¿ (æ•°æ®é›†: flower)
Generating (sequential):   0%|          | 0/306 [00:00<?, ?it/s]The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.
`torch_dtype` is deprecated! Use `dtype` instead!
[api_utils] åŠ è½½æ¨¡å‹: Qwen2.5-VL-7B-Instruct

Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s][A
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:03,  1.03it/s][A
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:01<00:02,  1.13it/s][A
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:02<00:01,  1.16it/s][A
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:03<00:00,  1.17it/s][A
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.59it/s][ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.35it/s]
The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating (sequential):   0%|          | 1/306 [00:20<1:41:52, 20.04s/it]Generating (sequential):   1%|          | 2/306 [00:32<1:18:06, 15.41s/it]Generating (sequential):   1%|          | 3/306 [00:40<1:02:06, 12.30s/it]Generating (sequential):   1%|â–         | 4/306 [00:45<46:40,  9.27s/it]  Generating (sequential):   2%|â–         | 5/306 [00:54<46:34,  9.28s/it]Generating (sequential):   2%|â–         | 6/306 [01:03<45:22,  9.07s/it]Generating (sequential):   2%|â–         | 7/306 [01:13<47:32,  9.54s/it]Generating (sequential):   3%|â–         | 8/306 [01:21<44:55,  9.04s/it]Generating (sequential):   3%|â–         | 9/306 [01:31<44:55,  9.08s/it]Generating (sequential):   3%|â–         | 10/306 [01:38<41:51,  8.48s/it]Generating (sequential):   4%|â–         | 11/306 [01:47<42:50,  8.71s/it]Generating (sequential):   4%|â–         | 12/306 [01:55<42:10,  8.61s/it]Generating (sequential):   4%|â–         | 13/306 [02:05<43:15,  8.86s/it]Generating (sequential):   5%|â–         | 14/306 [02:15<44:40,  9.18s/it]Generating (sequential):   5%|â–         | 15/306 [02:24<45:22,  9.36s/it]Generating (sequential):   5%|â–Œ         | 16/306 [02:36<48:12,  9.97s/it]Generating (sequential):   6%|â–Œ         | 17/306 [02:45<46:40,  9.69s/it]Generating (sequential):   6%|â–Œ         | 18/306 [02:55<46:32,  9.70s/it]Generating (sequential):   6%|â–Œ         | 19/306 [03:03<44:56,  9.40s/it]Generating (sequential):   7%|â–‹         | 20/306 [03:08<38:06,  7.99s/it]Generating (sequential):   7%|â–‹         | 21/306 [03:16<37:40,  7.93s/it]Generating (sequential):   7%|â–‹         | 22/306 [03:25<39:06,  8.26s/it]Generating (sequential):   8%|â–Š         | 23/306 [03:33<39:30,  8.38s/it]Generating (sequential):   8%|â–Š         | 24/306 [03:42<39:44,  8.45s/it]Generating (sequential):   8%|â–Š         | 25/306 [03:51<39:39,  8.47s/it]