å·²æ¿€æ´» conda ç¯å¢ƒ: autosep
============================================================
AutoSEP Pipeline
é…ç½®æ–‡ä»¶: /home/hdl/data/project/autosep/scripts/config.yaml
é¡¹ç›®æ ¹ç›®å½•: /home/hdl/data/project/autosep
æ—¥å¿—æ–‡ä»¶: /home/hdl/data/project/autosep/logs/pipeline_dog(1).log
============================================================
è®¾ç½® CUDA_VISIBLE_DEVICES=0
è°ƒè¯•æ¯”ä¾‹: train_ratio=10.0%, test_ratio=10.0%
AutoSEP æœ‰æ•ˆæ ·æœ¬æ•°: n_train=3, n_val=3, n_test=3
åˆ†ç±»è¯„ä¼°æœ‰æ•ˆæ ·æœ¬æ•°: n_test=3
è®¾ç½® AUTOSEP_MODEL=Qwen2.5-VL-7B-Instruct

============================================================
é…ç½®ä¿¡æ¯
============================================================
æ•°æ®é›†ç®€ç§°: dog
ç›®å½•å: dogs_120
å…¨ç§°: Stanford Dogs
ç±»åˆ«æ•°: 120
ç±»å‹: ç‹—å“ç§åˆ†ç±»
è·¯å¾„: /home/hdl/data/project/autosep/datasets/dogs_120 âœ“

è¿è¡Œå‚æ•°:
  æ•°æ®ç›®å½•: ./datasets
  æ¨¡å‹: Qwen2.5-VL-7B-Instruct
  GPU: 0
  å®éªŒç¼–å·: 1

æ”¯æŒçš„æ¨¡å‹:
  - Qwen2.5-VL-7B-Instruct (é»˜è®¤)
  - Qwen3-VL-8B-Instruct

æ”¯æŒçš„æ•°æ®é›†:
  ç»†ç²’åº¦: cub, dog, flower, car, pet, aircraft, food, birdsnap
  é€šç”¨:   caltech101, caltech256, dtd, eurosat, ucf, sun397
  ImageNet: imagenet_1k, imagenet_a, imagenet_r, imagenet_sketch, imagenet_v2
============================================================

å¼€å§‹å¤„ç†: æ•°æ®é›†=dog, æ¨¡å‹=Qwen2.5-VL-7B-Instruct
============================================================

[Step 1/2] è¿è¡Œ AutoSEP ä¼˜åŒ–...

[DatasetLoader] åŠ è½½æ•°æ®é›†: dog -> dogs_120
  - è·¯å¾„: /data/oldhome/gwj_sdc/hdl/project/autosep/datasets/dogs_120
  - åˆ’åˆ†æ–‡ä»¶: split_datasets_images.json
  - ç±»åˆ«æ•°: 120
  - è®­ç»ƒé›†: 16418 æ ·æœ¬
  - éªŒè¯é›†: 0 æ ·æœ¬
  - æµ‹è¯•é›†: 4162 æ ·æœ¬
[load_prompts] ä½¿ç”¨é»˜è®¤ prompt æ¨¡æ¿ (æ•°æ®é›†: dog)
Generating (sequential):   0%|          | 0/360 [00:00<?, ?it/s]The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.
`torch_dtype` is deprecated! Use `dtype` instead!
[api_utils] åŠ è½½æ¨¡å‹: Qwen2.5-VL-7B-Instruct

Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s][A
Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:04,  1.15s/it][A
Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:01<00:02,  1.03it/s][A
Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:02<00:01,  1.10it/s][A
Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:03<00:00,  1.11it/s][A
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.52it/s][ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.27it/s]
The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Generating (sequential):   0%|          | 1/360 [00:22<2:12:54, 22.21s/it]Generating (sequential):   1%|          | 2/360 [00:31<1:28:09, 14.78s/it]Generating (sequential):   1%|          | 3/360 [00:45<1:25:59, 14.45s/it]Generating (sequential):   1%|          | 4/360 [00:58<1:22:30, 13.91s/it]Generating (sequential):   1%|â–         | 5/360 [01:12<1:22:18, 13.91s/it]Generating (sequential):   2%|â–         | 6/360 [01:25<1:19:15, 13.43s/it]Generating (sequential):   2%|â–         | 7/360 [01:39<1:19:27, 13.51s/it]Generating (sequential):   2%|â–         | 8/360 [01:52<1:19:02, 13.47s/it]Generating (sequential):   2%|â–         | 9/360 [01:57<1:02:59, 10.77s/it]Generating (sequential):   3%|â–         | 10/360 [02:07<1:02:45, 10.76s/it]Generating (sequential):   3%|â–         | 11/360 [02:13<52:25,  9.01s/it]  Generating (sequential):   3%|â–         | 12/360 [02:23<54:27,  9.39s/it]Generating (sequential):   4%|â–         | 13/360 [02:37<1:02:39, 10.84s/it]Generating (sequential):   4%|â–         | 14/360 [02:50<1:06:04, 11.46s/it]Generating (sequential):   4%|â–         | 15/360 [03:03<1:08:42, 11.95s/it]Generating (sequential):   4%|â–         | 16/360 [03:13<1:04:53, 11.32s/it]Generating (sequential):   5%|â–         | 17/360 [03:26<1:07:35, 11.82s/it]Generating (sequential):   5%|â–Œ         | 18/360 [03:38<1:07:16, 11.80s/it]Generating (sequential):   5%|â–Œ         | 19/360 [03:52<1:10:49, 12.46s/it]Generating (sequential):   6%|â–Œ         | 20/360 [03:58<59:42, 10.54s/it]  Generating (sequential):   6%|â–Œ         | 21/360 [04:08<58:39, 10.38s/it]Generating (sequential):   6%|â–Œ         | 22/360 [04:18<57:58, 10.29s/it]